---
phase: 01-ledger-foundation-and-import-pipeline
plan: 02
type: execute
wave: 2
depends_on:
  - 01-01
files_modified:
  - src/compteqc/ingestion/rbc_cheques.py
  - src/compteqc/ingestion/rbc_carte.py
  - src/compteqc/ingestion/rbc_ofx.py
  - src/compteqc/ingestion/normalisation.py
  - src/compteqc/ingestion/__init__.py
  - src/compteqc/categorisation/moteur.py
  - src/compteqc/categorisation/regles.py
  - src/compteqc/categorisation/__init__.py
  - rules/categorisation.yaml
  - tests/fixtures/rbc_cheques_sample.csv
  - tests/fixtures/rbc_carte_sample.csv
  - tests/fixtures/rbc_sample.ofx
  - tests/test_importers.py
  - tests/test_categorisation.py
autonomous: true
requirements:
  - INGEST-01
  - INGEST-02
  - INGEST-03
  - INGEST-04
  - INGEST-05
  - CAT-01

must_haves:
  truths:
    - "Un fichier CSV de cheques RBC est parse en transactions Beancount avec montants Decimal corrects"
    - "Un fichier CSV de carte de credit RBC est parse en transactions Beancount avec montants Decimal corrects"
    - "Un fichier OFX/QFX RBC est parse en transactions Beancount avec FITID pour deduplication"
    - "Les transactions passent par le moteur de regles YAML et recoivent le bon compte ou Depenses:Non-Classe"
    - "Les fichiers importes sont archives dans data/processed/ avec metadata"
    - "Toutes les transactions produites passent bean-check quand inserees dans le ledger"
  artifacts:
    - path: "src/compteqc/ingestion/rbc_cheques.py"
      provides: "Importateur CSV pour compte-cheques RBC"
      contains: "RBCChequesImporter"
    - path: "src/compteqc/ingestion/rbc_carte.py"
      provides: "Importateur CSV pour carte de credit RBC"
      contains: "RBCCarteImporter"
    - path: "src/compteqc/ingestion/rbc_ofx.py"
      provides: "Importateur OFX/QFX pour RBC"
      contains: "RBCOfxImporter"
    - path: "src/compteqc/categorisation/moteur.py"
      provides: "Moteur de categorisation par regles YAML"
      contains: "MoteurRegles"
    - path: "rules/categorisation.yaml"
      provides: "Fichier de regles de categorisation (vide au depart)"
      contains: "regles"
  key_links:
    - from: "src/compteqc/ingestion/rbc_cheques.py"
      to: "src/compteqc/categorisation/moteur.py"
      via: "categorisation post-extraction"
      pattern: "MoteurRegles|categoriser"
    - from: "src/compteqc/ingestion/rbc_ofx.py"
      to: "src/compteqc/categorisation/moteur.py"
      via: "categorisation post-extraction"
      pattern: "MoteurRegles|categoriser"
    - from: "src/compteqc/categorisation/regles.py"
      to: "rules/categorisation.yaml"
      via: "chargement YAML"
      pattern: "yaml.safe_load|categorisation.yaml"
---

<objective>
Construire les trois importateurs RBC (CSV cheques, CSV carte credit, OFX/QFX) et le moteur de categorisation par regles YAML. A la fin de ce plan, un fichier bancaire peut etre parse en transactions Beancount valides, categorisees par regles ou marquees Non-Classe.

Purpose: C'est le coeur du pipeline d'ingestion. Sans importateurs fonctionnels, aucune donnee bancaire n'entre dans le ledger.
Output: Trois importateurs RBC testes, un moteur de categorisation par regles, des fixtures de test, et un fichier de regles YAML initial (vide, a peupler par l'utilisateur).
</objective>

<execution_context>
@/Users/philippebeliveau/.claude/get-shit-done/workflows/execute-plan.md
@/Users/philippebeliveau/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-ledger-foundation-and-import-pipeline/01-RESEARCH.md
@.planning/phases/01-ledger-foundation-and-import-pipeline/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Construire les importateurs CSV RBC (cheques et carte de credit) avec normalisation</name>
  <files>
    src/compteqc/ingestion/__init__.py
    src/compteqc/ingestion/normalisation.py
    src/compteqc/ingestion/rbc_cheques.py
    src/compteqc/ingestion/rbc_carte.py
    tests/fixtures/rbc_cheques_sample.csv
    tests/fixtures/rbc_carte_sample.csv
    tests/test_importers.py
  </files>
  <action>
  1. Creer tests/fixtures/rbc_cheques_sample.csv :
     Format RBC cheques : colonnes "Account Type","Account Number","Transaction Date","Cheque Number","Description 1","Description 2","CAD$","USD$"
     NOTE : Le format exact peut varier. Le research indique "Date","Description","Transaction","Debit","Credit","Total" mais les formats RBC business peuvent differer. Construire l'importateur avec detection flexible de colonnes headers. Inclure 5-10 transactions realistes :
     - Depot (revenu consultation)
     - Paiement fournisseur (Bell, Videotron)
     - Virement vers carte credit
     - Frais bancaires
     - Achat logiciel (GitHub, JetBrains)
     Les montants doivent etre coherents (debits negatifs ou dans colonne separee selon le format).

  2. Creer tests/fixtures/rbc_carte_sample.csv :
     Format RBC carte credit business : colonnes possibles "Transaction Date","Posting Date","Activity Type","Description","Amount"
     NOTE : Meme remarque que ci-dessus. Inclure 5-10 transactions :
     - Restaurant
     - Abonnement SaaS (AWS, DigitalOcean)
     - Fournitures de bureau
     - Deplacement (taxi, hotel)
     Les montants : depenses positives, credits/paiements negatifs (convention carte credit).

  3. Creer src/compteqc/ingestion/normalisation.py :
     - Fonction `nettoyer_beneficiaire(brut: str) -> str` :
       - Normalise les espaces
       - Retire les numeros de transaction/reference en fin de chaine
       - Capitalise correctement (Title Case)
     - Fonction `detecter_encodage(chemin: Path) -> str` :
       - Essaie UTF-8, puis Latin-1, puis Windows-1252
       - Retourne le nom de l'encodage qui fonctionne
     - Fonction `archiver_fichier(source: Path, dest_dir: Path) -> Path` :
       - Copie le fichier dans data/processed/YYYY-MM-DD/
       - Cree un fichier .meta.json a cote avec : date_import, hash_sha256, chemin_original, nombre_transactions
       - Retourne le chemin de destination
       - INGEST-05 : c'est ici que l'archivage se fait

  4. Creer src/compteqc/ingestion/rbc_cheques.py :
     - Classe `RBCChequesImporter` :
       - NE PAS heriter de csvbase.Importer si le format RBC utilise des colonnes Debit/Credit separees -- la recherche indique que csvbase attend une seule colonne amount. Ecrire un importateur custom heritant de `beangulp.Importer` si necessaire.
       - Methode `identify(filepath)` : verifier l'extension .csv ET les colonnes header (chercher les noms de colonnes RBC)
       - Methode `account(filepath)` : retourner "Actifs:Banque:RBC:Cheques"
       - Methode `extract(filepath, existing)` : parser le CSV, creer des objets `data.Transaction` Beancount
         - Chaque transaction a DEUX postings : un sur Actifs:Banque:RBC:Cheques, un sur Depenses:Non-Classe (la categorisation viendra apres)
         - Flag `!` (en attente de revue)
         - Metadata : source="rbc-cheques-csv", categorisation="non-classe", fichier_source=nom_du_fichier, ligne=numero_ligne
         - TOUS les montants via `Decimal(str_montant)` -- JAMAIS float
       - Gestion des encodages via normalisation.detecter_encodage()
     - DEDUPLICATION : Comparer les transactions extraites contre `existing` (parametre de extract). Utiliser date + montant + 20 premiers caracteres de narration. Logger les doublons trouves, ne pas les inclure dans les resultats. Pour chaque doublon detecte, ajouter un commentaire dans les metadonnees de log.

  5. Creer src/compteqc/ingestion/rbc_carte.py :
     - Classe `RBCCarteImporter` : meme structure que RBCChequesImporter
       - account : "Passifs:CartesCredit:RBC"
       - Attention aux signes : pour une carte credit, les achats sont des debits (augmentent le solde du), les paiements sont des credits
       - Metadata source="rbc-carte-csv"
       - Meme logique de deduplication

  6. Mettre a jour src/compteqc/ingestion/__init__.py :
     - Exporter RBCChequesImporter, RBCCarteImporter, archiver_fichier

  7. Creer/completer tests/test_importers.py :
     - Test identify() retourne True pour les bons fichiers, False pour les mauvais
     - Test extract() sur les fixtures : verifie le nombre de transactions, les montants (Decimal), les comptes, le flag !
     - Test que chaque transaction a exactement 2 postings
     - Test que les montants balancent (somme des postings = 0 pour chaque transaction)
     - Test de deduplication : importer deux fois le meme fichier, verifier que le deuxieme import retourne 0 nouvelles transactions
     - Test archiver_fichier : verifier que le fichier est copie et que .meta.json contient les bonnes infos
     - Test nettoyer_beneficiaire avec des cas reels (ex: "PAIEMENT INTERAC   CAFE XYZ  123456" -> "Cafe Xyz")
  </action>
  <verify>
  ```bash
  uv run pytest tests/test_importers.py -v
  uv run python -c "
from compteqc.ingestion.rbc_cheques import RBCChequesImporter
imp = RBCChequesImporter()
print('identify:', imp.identify('tests/fixtures/rbc_cheques_sample.csv'))
txns = imp.extract('tests/fixtures/rbc_cheques_sample.csv', [])
print(f'{len(txns)} transactions extraites')
for t in txns[:2]:
    print(f'  {t.date} | {t.narration} | {len(t.postings)} postings')
"
  uv run ruff check src/compteqc/ingestion/
  ```
  Les tests passent. L'importateur identifie et extrait les transactions correctement. Ruff ne signale pas d'erreur.
  </verify>
  <done>Les deux importateurs CSV (cheques et carte credit) parsent les fichiers RBC en transactions Beancount a 2 postings avec montants Decimal, deduplication, et archivage des fichiers sources.</done>
</task>

<task type="auto">
  <name>Task 2: Construire l'importateur OFX et le moteur de categorisation par regles YAML</name>
  <files>
    src/compteqc/ingestion/rbc_ofx.py
    src/compteqc/categorisation/moteur.py
    src/compteqc/categorisation/regles.py
    src/compteqc/categorisation/__init__.py
    rules/categorisation.yaml
    tests/fixtures/rbc_sample.ofx
    tests/test_importers.py
    tests/test_categorisation.py
  </files>
  <action>
  1. Creer tests/fixtures/rbc_sample.ofx :
     Creer un fichier OFX v1 (SGML) valide et minimal, simulant un releve RBC. Utiliser le format standard SGML OFX :
     ```
     OFXHEADER:100
     DATA:OFXSGML
     VERSION:102
     ...
     <STMTRS>
       <CURDEF>CAD
       <BANKACCTFROM>
         <BANKID>003
         <ACCTID>12345-6789012
         <ACCTTYPE>CHECKING
       </BANKACCTFROM>
       <BANKTRANLIST>
         <STMTTRN>
           <TRNTYPE>DEBIT
           <DTPOSTED>20260115
           <TRNAMT>-150.00
           <FITID>2026011500001
           <NAME>BELL CANADA
           <MEMO>PAIEMENT MENSUEL
         </STMTTRN>
         ...5-8 transactions...
       </BANKTRANLIST>
     </STMTRS>
     ```
     Inclure des FITID uniques pour chaque transaction. Utiliser des montants et dates coherents avec les fixtures CSV pour pouvoir tester la deduplication cross-format.

  2. Creer src/compteqc/ingestion/rbc_ofx.py :
     - Classe `RBCOfxImporter(beangulp.Importer)` :
       - `__init__(self, account: str, account_id: str)` : account est le nom Beancount, account_id est le ACCTID RBC
       - `identify(filepath)` : verifier extension .ofx/.qfx, parser avec ofxtools, verifier que l'ACCTID correspond
       - `account(filepath)` : retourner self.account_name
       - `extract(filepath, existing)` :
         - Parser avec `OFXTree().parse(filepath)` puis `.convert()`
         - Pour chaque transaction dans stmt.transactions :
           - Creer un `data.Transaction` Beancount avec 2 postings
           - Posting 1 : compte bancaire avec montant `tx.trnamt` (deja Decimal via ofxtools)
           - Posting 2 : Depenses:Non-Classe (montant oppose)
           - Flag `!`
           - Metadata : fitid=tx.fitid, source="rbc-ofx", categorisation="non-classe"
         - DEDUPLICATION OFX : Comparer FITID contre existing. Si un FITID existe deja dans les transactions existantes (chercher dans meta), c'est un doublon certain. Logger et exclure.
       - Gestion d'erreur : si le fichier OFX est invalide, lever une exception claire (pas un crash silencieux)

  3. Creer rules/categorisation.yaml :
     Fichier initial AVEC une structure valide mais des regles vides :
     ```yaml
     # Regles de categorisation automatique
     # Format : chaque regle a un nom, des conditions (regex sur payee/narration), et un compte cible
     # Les regles sont evaluees dans l'ordre ; la premiere correspondance gagne
     # Ajouter des regles au fur et a mesure des imports
     regles: []
     ```
     Per user decision : "Pas de pre-chargement de regles -- on commence vide et on batit au fur et a mesure des imports". Le fichier est vide mais valide.

  4. Creer src/compteqc/categorisation/regles.py :
     - Pydantic model `ConditionRegle` :
       - payee: str | None = None (regex pattern)
       - narration: str | None = None (regex pattern)
       - montant_min: Decimal | None = None
       - montant_max: Decimal | None = None
     - Pydantic model `Regle` :
       - nom: str
       - condition: ConditionRegle
       - compte: str (le compte Beancount cible)
       - confiance: float = 0.9 (entre 0 et 1)
     - Pydantic model `ConfigRegles` :
       - regles: list[Regle] = []
     - Fonction `charger_regles(chemin: Path) -> ConfigRegles` :
       - Charge le YAML, valide avec Pydantic
       - Retourne ConfigRegles (vide si le fichier contient `regles: []`)
       - Leve une erreur claire si le YAML est invalide

  5. Creer src/compteqc/categorisation/moteur.py :
     - Classe `MoteurRegles` :
       - `__init__(self, regles: ConfigRegles, comptes_valides: set[str])` :
         - Compile les regex des conditions
         - Stocke le set de comptes valides pour validation
       - `categoriser(payee: str, narration: str, montant: Decimal) -> ResultatCategorisation` :
         - Pour chaque regle dans l'ordre :
           - Tester le regex payee contre `f"{payee} {narration}".upper()`
           - Tester le regex narration si present
           - Tester montant_min/montant_max si presents
           - Si toutes les conditions d'une regle matchent :
             - Verifier que le compte cible est dans comptes_valides
             - Retourner ResultatCategorisation(compte=..., confiance=..., regle=..., source="regle")
         - Si aucune regle ne matche : retourner ResultatCategorisation(compte="Depenses:Non-Classe", confiance=0.0, regle=None, source="non-classe")
       - IMPORTANT : ne JAMAIS inventer un compte qui n'est pas dans comptes_valides. Si un compte de regle n'existe pas, logger un avertissement et traiter comme non-classe.
     - Dataclass `ResultatCategorisation` :
       - compte: str
       - confiance: float
       - regle: str | None (nom de la regle)
       - source: str ("regle" ou "non-classe")

  6. Creer une fonction `appliquer_categorisation(transactions: list[data.Transaction], moteur: MoteurRegles) -> list[data.Transaction]` dans src/compteqc/categorisation/__init__.py :
     - Pour chaque transaction qui a `categorisation: "non-classe"` dans ses metadata :
       - Appeler moteur.categoriser(payee, narration, montant)
       - Si le resultat n'est PAS non-classe :
         - Remplacer le posting Depenses:Non-Classe par le compte retourne
         - Mettre a jour metadata : categorisation=resultat.source, regle=resultat.regle, confiance=resultat.confiance
     - Retourne la liste de transactions modifiees
     - IMPORTANT : cette fonction ne mute PAS les transactions originales. Creer de nouvelles instances.

  7. Ajouter dans tests/test_importers.py :
     - Tests pour RBCOfxImporter : identify, extract, FITID dedup
     - Test d'integration : importer OFX puis re-importer le meme fichier, verifier 0 doublons

  8. Creer tests/test_categorisation.py :
     - Test charger_regles avec fichier vide (regles: [])
     - Test charger_regles avec des regles valides
     - Test MoteurRegles.categoriser avec des regles simples :
       - Ajouter une regle "Bell" -> "Depenses:Bureau:Internet-Telecom"
       - Verifier que "BELL CANADA" est categorise correctement
       - Verifier qu'un payee inconnu retourne Depenses:Non-Classe
     - Test que le moteur refuse un compte inexistant dans comptes_valides (avertissement + non-classe)
     - Test appliquer_categorisation : verifier que les postings sont mis a jour
     - Test que les transactions originales ne sont PAS mutees
  </action>
  <verify>
  ```bash
  uv run pytest tests/test_importers.py tests/test_categorisation.py -v
  uv run python -c "
from compteqc.ingestion.rbc_ofx import RBCOfxImporter
imp = RBCOfxImporter(account='Actifs:Banque:RBC:Cheques', account_id='12345-6789012')
print('identify:', imp.identify('tests/fixtures/rbc_sample.ofx'))
txns = imp.extract('tests/fixtures/rbc_sample.ofx', [])
print(f'{len(txns)} transactions OFX')
for t in txns[:2]:
    print(f'  {t.date} | FITID={t.meta.get(\"fitid\")} | {t.narration}')
"
  uv run ruff check src/compteqc/ingestion/ src/compteqc/categorisation/
  ```
  Tous les tests passent. L'importateur OFX extrait les transactions avec FITID. Le moteur de categorisation fonctionne avec des regles vides (tout va en Non-Classe).
  </verify>
  <done>Les trois importateurs RBC (CSV cheques, CSV carte credit, OFX) et le moteur de categorisation par regles YAML sont fonctionnels et testes. Les transactions sont normalisees, categorisees (ou Non-Classe), et les fichiers sources sont archives.</done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_importers.py tests/test_categorisation.py -v` -- tous les tests passent
2. Les trois importateurs identifient et extraient les transactions de leurs fixtures respectives
3. Chaque transaction extraite a exactement 2 postings qui balancent
4. La deduplication OFX fonctionne par FITID
5. La deduplication CSV fonctionne par date+montant+narration
6. Le moteur de regles retourne Depenses:Non-Classe quand aucune regle ne matche
7. Le moteur de regles categorise correctement quand une regle matche
8. L'archivage copie les fichiers et cree les .meta.json
9. Aucun montant n'utilise float (tous Decimal)
</verification>

<success_criteria>
- Les fichiers RBC (CSV et OFX) sont correctement parses en transactions Beancount
- La deduplication empeche les imports en double
- Le moteur de regles YAML categorise ou marque Non-Classe
- Les fichiers sources sont archives avec metadata
- Tous les tests passent
</success_criteria>

<output>
After completion, create `.planning/phases/01-ledger-foundation-and-import-pipeline/01-02-SUMMARY.md`
</output>
