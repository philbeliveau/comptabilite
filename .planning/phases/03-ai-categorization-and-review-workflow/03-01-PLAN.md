---
phase: 03-ai-categorization-and-review-workflow
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/compteqc/categorisation/pipeline.py
  - src/compteqc/categorisation/ml.py
  - src/compteqc/categorisation/capex.py
  - tests/test_pipeline.py
  - tests/test_capex.py
autonomous: true
requirements:
  - CAT-02
  - CAT-04
  - CAT-05
  - CAT-09

must_haves:
  truths:
    - "Pipeline cascades through rules -> ML -> LLM tiers, each processing only uncategorized remainder"
    - "ML tier provides probability-based confidence scores via SVC(probability=True)"
    - "ML tier is gracefully skipped when no training data exists (cold start)"
    - "Every pipeline result carries a confidence score and source tag (regle/ml/llm/non-classe)"
    - "Transactions below 80% confidence are marked for mandatory review"
    - "Transactions 80-95% go to pending queue, above 95% are auto-approved"
    - "Transactions >$500 or matching known vendor patterns are flagged as potential CAPEX with suggested CCA class"
    - "Tier disagreement (ML and LLM suggest different accounts) forces mandatory review"
  artifacts:
    - path: "src/compteqc/categorisation/pipeline.py"
      provides: "PipelineCategorisation orchestrator with tier cascade and threshold logic"
      contains: "PipelineCategorisation"
    - path: "src/compteqc/categorisation/ml.py"
      provides: "PredicteurML wrapper around smart_importer with confidence scoring"
      contains: "PredicteurML"
    - path: "src/compteqc/categorisation/capex.py"
      provides: "DetecteurCAPEX with amount threshold and vendor pattern matching"
      contains: "DetecteurCAPEX"
    - path: "tests/test_pipeline.py"
      provides: "Pipeline orchestration tests"
    - path: "tests/test_capex.py"
      provides: "CAPEX detection tests"
  key_links:
    - from: "src/compteqc/categorisation/pipeline.py"
      to: "src/compteqc/categorisation/moteur.py"
      via: "MoteurRegles.categoriser() as first tier"
      pattern: "self._regles.categoriser"
    - from: "src/compteqc/categorisation/pipeline.py"
      to: "src/compteqc/categorisation/ml.py"
      via: "PredicteurML.predire() as second tier"
      pattern: "self._ml.*predire"
    - from: "src/compteqc/categorisation/pipeline.py"
      to: "src/compteqc/categorisation/capex.py"
      via: "DetecteurCAPEX.verifier() on every result"
      pattern: "self._capex.verifier"
---

<objective>
Build the three-tier categorization pipeline orchestrator with ML prediction wrapper and CAPEX detector.

Purpose: This is the core engine that cascades transactions through rules -> ML -> LLM tiers with confidence scoring, threshold-based routing, and CAPEX flagging. The LLM tier interface is defined here but implemented in Plan 03-02.

Output: Working pipeline with ML and CAPEX tiers, tested via TDD. The LLM tier is accepted as an optional dependency (protocol/interface) so the pipeline works without it.
</objective>

<execution_context>
@/Users/philippebeliveau/.claude/get-shit-done/workflows/execute-plan.md
@/Users/philippebeliveau/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-categorization-and-review-workflow/03-RESEARCH.md
@.planning/phases/03-ai-categorization-and-review-workflow/03-CONTEXT.md
@src/compteqc/categorisation/moteur.py
@src/compteqc/categorisation/__init__.py
@src/compteqc/quebec/dpa/classes.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install smart-importer dependency and create ML wrapper with confidence scoring</name>
  <files>
    src/compteqc/categorisation/ml.py
    tests/test_pipeline.py
  </files>
  <action>
First install the dependency: `uv add smart-importer`

Create `src/compteqc/categorisation/ml.py` with class `PredicteurML`:

1. **Subclass smart_importer's EntryPredictor** and override `define_pipeline()` to use `SVC(kernel="linear", probability=True)` instead of the default SVC without probability support. This enables Platt scaling for `predict_proba()`.

2. Key attributes and methods:
   - `MIN_TRAINING_SIZE = 20` (class constant, configurable)
   - `est_entraine: bool` property -- returns True only if pipeline has been fitted
   - `entrainer(entries: list[data.Directive])` -- trains on existing approved beancount entries (filters out `#pending` tagged transactions). Uses smart_importer's training data extraction patterns. Sets `est_entraine = True` on success.
   - `predire(payee: str, narration: str, montant: Decimal) -> ResultatML` -- returns predicted account + confidence score (probability from `predict_proba`). Raises or returns None if not trained.
   - `ResultatML` frozen dataclass: `compte: str, confiance: float`

3. Handle cold start: if training data has fewer than `MIN_TRAINING_SIZE` entries or fewer than 2 distinct accounts, `entrainer()` should log a warning and leave `est_entraine = False`.

4. The `weights` for feature extraction should be `{"narration": 1.0, "payee": 0.8}` per research recommendation.

5. If smart_importer's EntryPredictor doesn't work standalone outside beangulp, fall back to building the sklearn pipeline directly (CountVectorizer + SVC with probability). The key is that `predire()` works with payee+narration text and returns account+confidence.

Write initial failing tests in `tests/test_pipeline.py` for:
- ML prediction with sufficient training data returns account + confidence
- ML cold start (no data) returns `est_entraine = False`
- ML confidence is a float between 0 and 1
Then implement until tests pass.
  </action>
  <verify>
`cd /Users/philippebeliveau/Desktop/Notebook/comptabilite && uv run pytest tests/test_pipeline.py -v` passes all ML-related tests.
  </verify>
  <done>PredicteurML wraps smart_importer (or direct sklearn if needed) with probability-based confidence scores, handles cold start gracefully, and passes TDD tests.</done>
</task>

<task type="auto">
  <name>Task 2: Create CAPEX detector and pipeline orchestrator with threshold routing</name>
  <files>
    src/compteqc/categorisation/capex.py
    src/compteqc/categorisation/pipeline.py
    tests/test_capex.py
    tests/test_pipeline.py
  </files>
  <action>
**CAPEX Detector** (`src/compteqc/categorisation/capex.py`):

Create `DetecteurCAPEX` class:
- Constructor takes `seuil_montant: Decimal = Decimal("500")` and `patrons_vendeurs: list[str]` (default: ["apple", "dell", "b&h", "lenovo", "microsoft surface", "logitech", "samsung", "lg electronics"])
- `verifier(montant: Decimal, payee: str, narration: str) -> ResultatCAPEX`
- `ResultatCAPEX` frozen dataclass: `est_capex: bool, raison: str | None, classe_suggeree: int | None`
- Logic: flag if `abs(montant) >= seuil_montant` OR if any vendor pattern matches payee/narration (case-insensitive)
- CCA class suggestion: import `CLASSES_DPA` from `compteqc.quebec.dpa.classes` and use keyword matching:
  - "ordinateur", "laptop", "macbook", "imac", "computer" -> class 50
  - "meuble", "bureau", "chaise", "desk", "chair", "furniture" -> class 8
  - "vehicule", "auto", "car" -> class 10
  - "logiciel", "software", "licence" -> class 12
  - "telephone", "phone", "iphone" -> class 50
  - Default for unknown CAPEX: None (human decides)

**Pipeline Orchestrator** (`src/compteqc/categorisation/pipeline.py`):

Create `ResultatPipeline` frozen dataclass extending the concept from `ResultatCategorisation`:
- `compte: str`
- `confiance: float`
- `source: str` -- "regle", "ml", "llm", "non-classe"
- `regle: str | None` -- rule name if source is "regle"
- `est_capex: bool`
- `classe_dpa: int | None` -- suggested CCA class
- `revue_obligatoire: bool` -- True if confidence <80% or tier disagreement
- `suggestions: dict | None` -- when ML and LLM disagree, contains {"ml": (compte, conf), "llm": (compte, conf)}

Create `PipelineCategorisation` class:
- Constructor: `moteur_regles: MoteurRegles, predicteur_ml: PredicteurML | None, classificateur_llm: Any | None, detecteur_capex: DetecteurCAPEX`
  - The LLM classifier is typed as `Any` or a Protocol with a `classifier(payee, narration, montant) -> ResultatLLM` method. This allows Plan 03-02 to plug in the real implementation.
- `SEUIL_AUTO_APPROUVE = 0.95`
- `SEUIL_REVUE_OPTIONNELLE = 0.80`
- `categoriser(payee: str, narration: str, montant: Decimal) -> ResultatPipeline`:
  1. Tier 1: Call `moteur_regles.categoriser()`. If source == "regle", return immediately with confiance=1.0, run CAPEX check.
  2. Tier 2: If `predicteur_ml` is not None and `est_entraine`, call `predire()`. Store result.
  3. Tier 3: If `classificateur_llm` is not None, call `classifier()`. Store result.
  4. Resolution logic:
     - If only ML result: use it directly
     - If only LLM result: use it directly
     - If both agree (same account): use higher confidence
     - If both disagree: set `revue_obligatoire = True`, store both in `suggestions`
     - If neither: source = "non-classe", confiance = 0.0
  5. Apply CAPEX check on final result.
  6. Set `revue_obligatoire` based on confidence thresholds (< 0.80 = True).

- `determiner_destination(resultat: ResultatPipeline) -> str`:
  Returns one of: "direct" (rules or >95%), "pending" (80-95% or CAPEX), "revue" (mandatory <80% or disagreement). This is used by Plan 03-02 to route transactions.

Write TDD tests in `tests/test_capex.py`:
- Amount above $500 is flagged
- Known vendor (Apple) below $500 is flagged
- Unknown vendor below $500 is NOT flagged
- CCA class suggestions (computer -> 50, furniture -> 8)

Add TDD tests in `tests/test_pipeline.py`:
- Rule match bypasses ML/LLM, returns confiance=1.0
- ML-only result with >95% confidence -> destination "direct"
- ML-only result with 85% confidence -> destination "pending"
- ML-only result with 70% confidence -> destination "revue"
- ML+LLM agreement -> higher confidence used
- ML+LLM disagreement -> revue_obligatoire=True, both suggestions preserved
- No ML, no LLM -> non-classe
- Cold start (ML untrained, no LLM) -> non-classe
- CAPEX flag set on results for qualifying transactions
  </action>
  <verify>
`cd /Users/philippebeliveau/Desktop/Notebook/comptabilite && uv run pytest tests/test_pipeline.py tests/test_capex.py -v` all pass. `uv run ruff check src/compteqc/categorisation/pipeline.py src/compteqc/categorisation/capex.py` no errors.
  </verify>
  <done>Pipeline orchestrator cascades rules->ML->LLM with correct threshold routing (direct/pending/revue). CAPEX detector flags >$500 and known vendors with CCA class suggestions. All confidence/source/disagreement logic tested.</done>
</task>

</tasks>

<verification>
- `uv run pytest tests/test_pipeline.py tests/test_capex.py -v` -- all tests pass
- `uv run ruff check src/compteqc/categorisation/` -- no lint errors
- Pipeline handles cold start (no ML, no LLM) without errors
- ResultatPipeline always has a valid source tag and confidence score
- CAPEX detector correctly suggests CCA classes for known asset types
</verification>

<success_criteria>
- PredicteurML wraps SVC with probability=True and provides confidence scores
- PipelineCategorisation cascades through 3 tiers correctly
- Threshold routing: <80% mandatory review, 80-95% pending, >95% auto-approve
- Tier disagreement forces mandatory review with both suggestions preserved
- CAPEX detection works by amount threshold + vendor pattern + CCA class suggestion
- All behavior verified by TDD tests
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-categorization-and-review-workflow/03-01-SUMMARY.md`
</output>
