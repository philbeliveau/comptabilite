---
phase: 03-ai-categorization-and-review-workflow
plan: 02
type: execute
wave: 2
depends_on:
  - "03-01"
files_modified:
  - src/compteqc/categorisation/llm.py
  - src/compteqc/categorisation/pending.py
  - src/compteqc/cli/importer.py
  - tests/test_llm.py
  - tests/test_pending.py
autonomous: true
requirements:
  - CAT-03
  - CAT-06
  - CAT-08
  - CAT-11
  - CLI-02
user_setup:
  - service: anthropic
    why: "LLM categorization of edge-case transactions via Claude API"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys (https://console.anthropic.com/settings/keys)"

must_haves:
  truths:
    - "Claude LLM categorizes transactions constrained to the closed chart of accounts list"
    - "LLM receives rich context: transaction, chart of accounts, vendor history, similar transactions"
    - "LLM proposes account classification only -- GST/QST never computed by LLM"
    - "LLM categorizations are stored as JSONL with prompt, response, timestamp, and model for drift detection"
    - "AI-categorized transactions go to pending.beancount with #pending tag"
    - "Import CLI command runs the full pipeline (rules -> ML -> LLM) at import time"
    - "If ANTHROPIC_API_KEY is missing, LLM tier is skipped with a warning (graceful degradation)"
    - "Auto-approved transactions (>95% confidence) go directly to monthly files with audit metadata"
  artifacts:
    - path: "src/compteqc/categorisation/llm.py"
      provides: "ClassificateurLLM using Anthropic structured output"
      contains: "ClassificateurLLM"
    - path: "src/compteqc/categorisation/pending.py"
      provides: "Pending file management (write, read, move to monthly)"
      contains: "ecrire_pending"
    - path: "data/llm_log/categorisations.jsonl"
      provides: "LLM categorization log for drift detection"
    - path: "tests/test_llm.py"
      provides: "LLM classifier tests (mocked API)"
    - path: "tests/test_pending.py"
      provides: "Pending file management tests"
  key_links:
    - from: "src/compteqc/categorisation/llm.py"
      to: "anthropic SDK"
      via: "client.messages.parse() with Pydantic output_format"
      pattern: "messages.parse"
    - from: "src/compteqc/cli/importer.py"
      to: "src/compteqc/categorisation/pipeline.py"
      via: "PipelineCategorisation replaces direct appliquer_categorisation"
      pattern: "PipelineCategorisation"
    - from: "src/compteqc/categorisation/pending.py"
      to: "src/compteqc/ledger/fichiers.py"
      via: "ecrire_transactions and chemin_fichier_mensuel for approved transactions"
      pattern: "ecrire_transactions|chemin_fichier_mensuel"
---

<objective>
Implement the LLM classification tier, pending transaction staging, and integrate the full pipeline into the import CLI command.

Purpose: Completes the categorization pipeline by adding Claude LLM as the third tier, creates the pending.beancount staging mechanism for AI-categorized transactions, stores LLM logs for drift detection, and rewires the import command to use the full pipeline instead of rules-only categorization.

Output: Working end-to-end import flow: file -> extract -> rules -> ML -> LLM -> route to direct/pending/review. LLM categorizations logged as JSONL.
</objective>

<execution_context>
@/Users/philippebeliveau/.claude/get-shit-done/workflows/execute-plan.md
@/Users/philippebeliveau/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-categorization-and-review-workflow/03-RESEARCH.md
@.planning/phases/03-ai-categorization-and-review-workflow/03-01-SUMMARY.md
@src/compteqc/categorisation/pipeline.py
@src/compteqc/categorisation/ml.py
@src/compteqc/categorisation/capex.py
@src/compteqc/categorisation/__init__.py
@src/compteqc/cli/importer.py
@src/compteqc/ledger/fichiers.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create LLM classifier with structured output and JSONL logging</name>
  <files>
    src/compteqc/categorisation/llm.py
    tests/test_llm.py
  </files>
  <action>
First install the dependency: `uv add anthropic`

Create `src/compteqc/categorisation/llm.py`:

1. **Pydantic response model** `ResultatClassificationLLM(BaseModel)`:
   - `compte: str` -- Beancount account name
   - `confiance: float` (ge=0.0, le=1.0)
   - `raisonnement: str` -- brief explanation
   - `est_capex: bool` (default False)

2. **ResultatLLM** frozen dataclass (internal result):
   - `compte: str, confiance: float, raisonnement: str, est_capex: bool`

3. **ClassificateurLLM** class:
   - Constructor: `comptes_valides: list[str]`, `chemin_log: Path = Path("data/llm_log/categorisations.jsonl")`, `modele: str = "claude-sonnet-4-5-20250929"`
   - Lazily initializes `anthropic.Anthropic()` client (reads ANTHROPIC_API_KEY from env)
   - `est_disponible: bool` property -- True if ANTHROPIC_API_KEY env var is set
   - `classifier(payee: str, narration: str, montant: Decimal, historique_vendeur: list[dict] | None = None, transactions_similaires: list[dict] | None = None) -> ResultatLLM`:
     a. Build rich prompt with: transaction details, full chart of accounts with descriptions, vendor history, similar transactions
     b. Call `client.messages.parse(model=self._modele, max_tokens=256, messages=[...], output_format=ResultatClassificationLLM)`
     c. **Validate** returned `compte` against `comptes_valides` set. If invalid, return with `compte="Depenses:Non-Classe"` and `confiance=0.1`
     d. Log to JSONL (see below)
     e. Return `ResultatLLM`

   - LLM prompt must explicitly state:
     - "Choose ONLY from the valid accounts listed"
     - "Set est_capex=true only for capital asset purchases (computers, furniture, vehicles, etc.)"
     - "Your confidence should reflect how certain you are about the classification"
     - Never mention GST/QST/tax computation

4. **JSONL logging** `_enregistrer_log(self, payee, narration, montant, prompt, response, resultat)`:
   - Create parent dir if needed: `self._chemin_log.parent.mkdir(parents=True, exist_ok=True)`
   - Append one JSON line with: `timestamp` (ISO), `payee`, `narration`, `montant` (str), `prompt_hash` (sha256 of prompt), `modele`, `compte`, `confiance`, `raisonnement`, `est_capex`, `tokens_utilises` (from response usage)
   - Use atomic append (open with 'a')

5. **Graceful degradation**: If ANTHROPIC_API_KEY is not set, `est_disponible` returns False and the pipeline (from 03-01) skips this tier. If API call fails (network error, rate limit), catch exception, log warning, return `ResultatLLM(compte="Depenses:Non-Classe", confiance=0.0, raisonnement="Erreur API", est_capex=False)`.

Write tests in `tests/test_llm.py`:
- Mock `anthropic.Anthropic` to avoid real API calls
- Test valid classification returns correct ResultatLLM
- Test invalid account from LLM falls back to Non-Classe with low confidence
- Test JSONL log file is created and contains expected fields
- Test graceful degradation when API key missing (est_disponible = False)
- Test API error handling returns Non-Classe result
  </action>
  <verify>
`cd /Users/philippebeliveau/Desktop/Notebook/comptabilite && uv run pytest tests/test_llm.py -v` all pass. No real API calls made (all mocked).
  </verify>
  <done>ClassificateurLLM uses Anthropic structured output to classify transactions, validates against chart of accounts, logs all interactions to JSONL, handles errors gracefully.</done>
</task>

<task type="auto">
  <name>Task 2: Create pending file management and integrate full pipeline into import CLI</name>
  <files>
    src/compteqc/categorisation/pending.py
    src/compteqc/cli/importer.py
    src/compteqc/categorisation/__init__.py
    tests/test_pending.py
  </files>
  <action>
**Pending file management** (`src/compteqc/categorisation/pending.py`):

1. `ecrire_pending(chemin_pending: Path, transactions: list[data.Transaction], resultats: list[ResultatPipeline]) -> int`:
   - Add `#pending` tag to each transaction
   - Add metadata: `source_ia` (ml/llm), `confiance` (str), `compte_propose` (the AI-suggested account)
   - If CAPEX flagged: add metadata `capex="oui"`, `classe_dpa_suggeree` (str)
   - If tier disagreement: add metadata `suggestion_ml`, `suggestion_llm`
   - Write to pending.beancount using `ecrire_transactions`
   - Ensure pending.beancount has Beancount v3 name_* options header (same pattern as monthly files)
   - Return count of transactions written

2. `lire_pending(chemin_pending: Path) -> list[data.Transaction]`:
   - Load pending.beancount via `beancount.loader.load_file()`
   - Return only `data.Transaction` entries with `#pending` tag
   - Return empty list if file doesn't exist

3. `approuver_transactions(chemin_pending: Path, chemin_main: Path, indices: list[int]) -> int`:
   - Load pending transactions
   - For selected indices: remove `#pending` tag, change flag from `!` to `*`
   - Write approved transactions to appropriate monthly files using `chemin_fichier_mensuel` + `ecrire_transactions`
   - Rewrite pending.beancount with remaining transactions only
   - Validate ledger after move. If invalid, rollback both files.
   - Return count of approved transactions

4. `rejeter_transactions(chemin_pending: Path, indices: list[int]) -> int`:
   - Remove selected transactions from pending.beancount entirely
   - Return count of rejected transactions

5. Ensure `pending.beancount` include directive is added to `main.beancount` when first pending transaction is written (use `ajouter_include`).

**Integrate pipeline into import CLI** (`src/compteqc/cli/importer.py`):

Modify `_importer_avec()` to replace the current rules-only categorization with the full pipeline:

1. After extracting transactions, create `PipelineCategorisation` with:
   - `MoteurRegles` (existing)
   - `PredicteurML` (try to train from existing ledger entries; skip if cold start)
   - `ClassificateurLLM` (create if ANTHROPIC_API_KEY available; None otherwise)
   - `DetecteurCAPEX` (always available)

2. For each transaction, call `pipeline.categoriser()` and `pipeline.determiner_destination()`:
   - "direct" -> write to monthly file immediately (rules or >95% AI confidence)
   - "pending" -> collect for pending.beancount (80-95%)
   - "revue" -> collect for pending.beancount with mandatory review flag (<80% or disagreement)

3. Write pending transactions to `pending.beancount` using `ecrire_pending()`

4. Update import summary table to show: categorisees par regles, categorisees par IA (auto-approuvees), en attente de revision (pending), non-classees. Show pending count and hint about `cqc reviser` command.

5. Keep existing rollback, git commit, and archival logic. Add pending file to git commit if it was modified.

6. If ML or LLM tiers are unavailable, show a brief info message (not an error) explaining what was skipped and why.

Update `src/compteqc/categorisation/__init__.py` to export the new pipeline classes.

Write tests in `tests/test_pending.py`:
- Write transactions to pending, read them back, verify #pending tag
- Approve transactions: verify they move to monthly file and are removed from pending
- Reject transactions: verify they are removed from pending
- Empty pending file handled gracefully
  </action>
  <verify>
`cd /Users/philippebeliveau/Desktop/Notebook/comptabilite && uv run pytest tests/test_pending.py tests/test_llm.py -v` all pass. `uv run pytest tests/test_cli.py -v` existing CLI tests still pass (import behavior preserved for rule-matched transactions). `uv run ruff check src/compteqc/` no errors.
  </verify>
  <done>Full pipeline integrated into import CLI. Pending.beancount staging works with #pending tags. LLM logs stored as JSONL. Import summary shows tiered categorization results. Graceful degradation when ML or LLM unavailable.</done>
</task>

</tasks>

<verification>
- `uv run pytest tests/test_llm.py tests/test_pending.py -v` -- all tests pass
- `uv run pytest tests/test_cli.py -v` -- existing import tests still pass
- `uv run ruff check src/compteqc/` -- no lint errors
- LLM is mocked in all tests (no real API calls)
- pending.beancount round-trips correctly (write -> read -> approve -> verify moved)
- Import with no ANTHROPIC_API_KEY skips LLM with info message (not error)
</verification>

<success_criteria>
- ClassificateurLLM uses Anthropic structured output constrained to chart of accounts
- Invalid LLM account responses fall back to Non-Classe with low confidence
- All LLM interactions logged to JSONL with prompt hash, model, and token usage
- pending.beancount correctly stages AI-categorized transactions with #pending tag
- Import CLI runs full pipeline and routes transactions to direct/pending based on confidence
- Import summary shows breakdown by tier (rules, AI auto-approved, pending, non-classe)
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-categorization-and-review-workflow/03-02-SUMMARY.md`
</output>
