---
phase: 03-ai-categorization-and-review-workflow
plan: 03
type: execute
wave: 3
depends_on:
  - "03-02"
files_modified:
  - src/compteqc/cli/reviser.py
  - src/compteqc/categorisation/feedback.py
  - src/compteqc/cli/app.py
  - tests/test_reviser.py
  - tests/test_feedback.py
autonomous: true
requirements:
  - CAT-07
  - CAT-08
  - CAT-10
  - CLI-03

must_haves:
  truths:
    - "User can review pending transactions in a Rich table showing account, confidence, source, vendor history, and CAPEX flags"
    - "User can approve, reject, or recategorize individual or batched pending transactions via CLI"
    - "Approved transactions move from pending.beancount to monthly ledger files with #pending tag removed"
    - "User corrections are tracked and after 2 identical corrections (same vendor -> same account), a new rule is auto-generated in categorisation.yaml"
    - "Mandatory review items (<80%) are visually distinct from optional review items (80-95%)"
    - "Corrections accept optional notes for later analysis"
    - "Auto-generated rules are silently appended -- no user confirmation needed"
  artifacts:
    - path: "src/compteqc/cli/reviser.py"
      provides: "CLI commands for batch review, approve, reject, recategorize"
      contains: "reviser_app"
    - path: "src/compteqc/categorisation/feedback.py"
      provides: "Correction tracking and auto-rule generation"
      contains: "enregistrer_correction"
    - path: "tests/test_reviser.py"
      provides: "Review CLI tests"
    - path: "tests/test_feedback.py"
      provides: "Feedback loop and auto-rule generation tests"
  key_links:
    - from: "src/compteqc/cli/reviser.py"
      to: "src/compteqc/categorisation/pending.py"
      via: "lire_pending, approuver_transactions, rejeter_transactions"
      pattern: "lire_pending|approuver_transactions|rejeter_transactions"
    - from: "src/compteqc/cli/reviser.py"
      to: "src/compteqc/categorisation/feedback.py"
      via: "enregistrer_correction on recategorize"
      pattern: "enregistrer_correction"
    - from: "src/compteqc/categorisation/feedback.py"
      to: "src/compteqc/categorisation/regles.py"
      via: "Append auto-generated rules to categorisation.yaml"
      pattern: "categorisation.yaml|charger_regles"
    - from: "src/compteqc/cli/app.py"
      to: "src/compteqc/cli/reviser.py"
      via: "app.add_typer(reviser_app)"
      pattern: "reviser_app"
---

<objective>
Build the CLI review workflow for pending transactions and the feedback loop that auto-generates categorization rules from user corrections.

Purpose: Closes the human-in-the-loop cycle. Users review AI-categorized transactions, approve/reject/recategorize them, and their corrections feed back into the rule engine for continuous improvement. This is the last plan in Phase 3.

Output: Working `cqc reviser` CLI with batch review table, approve/reject/recategorize actions, and auto-rule generation after 2 identical corrections.
</objective>

<execution_context>
@/Users/philippebeliveau/.claude/get-shit-done/workflows/execute-plan.md
@/Users/philippebeliveau/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-categorization-and-review-workflow/03-RESEARCH.md
@.planning/phases/03-ai-categorization-and-review-workflow/03-02-SUMMARY.md
@src/compteqc/categorisation/pending.py
@src/compteqc/categorisation/regles.py
@src/compteqc/cli/app.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create feedback module with correction tracking and auto-rule generation</name>
  <files>
    src/compteqc/categorisation/feedback.py
    tests/test_feedback.py
  </files>
  <action>
Create `src/compteqc/categorisation/feedback.py`:

1. **Correction tracking** with persistent JSON storage:
   - `CHEMIN_HISTORIQUE_DEFAUT = Path("data/corrections/historique.json")`
   - `SEUIL_AUTO_REGLE = 2` (auto-generate rule after 2 identical corrections)

2. `enregistrer_correction(chemin_historique: Path, vendeur: str, compte_corrige: str, compte_original: str | None = None, note: str | None = None) -> Regle | None`:
   - Load existing history from JSON file (create if missing)
   - Key by normalized vendor name: `vendeur.upper().strip()`
   - Track count per vendor -> account mapping: `{vendor: {account: count, ...}, ...}`
   - Also store last correction timestamp and notes list
   - If count for this vendor->account reaches `SEUIL_AUTO_REGLE`:
     - Generate a new `Regle` with:
       - `nom`: `"auto-{normalized_vendor[:20]}"` (slugified, no spaces)
       - `condition`: `ConditionRegle(payee=re.escape(vendor))`
       - `compte`: the corrected account
       - `confiance`: 0.95
     - Return the generated rule
   - Save updated history atomically (write to .tmp then rename)
   - Return None if threshold not met

3. `ajouter_regle_auto(chemin_regles: Path, regle: Regle) -> None`:
   - Load existing YAML rules file
   - Check for duplicate (same vendor pattern already exists) -- skip if duplicate
   - Append new rule to the list
   - Write back to YAML
   - Log info message: "Nouvelle regle auto-generee: {regle.nom} -> {regle.compte}"

4. `charger_historique(chemin: Path) -> dict`:
   - Load and return the correction history JSON
   - Return empty dict if file doesn't exist

Write tests in `tests/test_feedback.py`:
- First correction for vendor: no rule generated, count = 1
- Second identical correction (same vendor, same account): rule generated with correct fields
- Different account for same vendor: separate counter, no rule yet
- Auto-generated rule has correct regex pattern and confidence
- Duplicate rule detection (don't add same vendor rule twice)
- History persists across calls (write to tmp_path)
- Notes are stored with corrections
  </action>
  <verify>
`cd /Users/philippebeliveau/Desktop/Notebook/comptabilite && uv run pytest tests/test_feedback.py -v` all pass.
  </verify>
  <done>Correction history persists to JSON, auto-generates YAML rules after 2 identical corrections, prevents duplicate rules, stores correction notes.</done>
</task>

<task type="auto">
  <name>Task 2: Create review CLI with batch table display and approve/reject/recategorize actions</name>
  <files>
    src/compteqc/cli/reviser.py
    src/compteqc/cli/app.py
    tests/test_reviser.py
  </files>
  <action>
**Review CLI** (`src/compteqc/cli/reviser.py`):

Create a Typer sub-app `reviser_app` with these commands:

1. `cqc reviser liste` (default command):
   - Load pending transactions from `pending.beancount` via `lire_pending()`
   - Display Rich table with columns per research recommendation:
     1. `#` (1-indexed row number for selection)
     2. `Date`
     3. `Montant` (right-aligned, red for negative/debits)
     4. `Beneficiaire` (truncated to 25 chars)
     5. `Compte propose` (from metadata `compte_propose`)
     6. `Conf.` (confidence %, colored: red <80%, yellow 80-95%, green >95%)
     7. `Source` (from metadata `source_ia`: ml/llm)
     8. `Drapeaux` (CAPEX if metadata `capex=="oui"`, `!` if mandatory review)
   - Show mandatory review items (<80%) first, then separator `---`, then optional items (80-95%)
   - Show summary footer: "X transactions en attente (Y obligatoires, Z optionnelles)"
   - If no pending transactions: "Aucune transaction en attente de revision."

   Optional filters via CLI options:
   - `--vendeur TEXT` -- filter by vendor substring
   - `--confiance-min FLOAT` / `--confiance-max FLOAT` -- filter by confidence range
   - `--obligatoire` -- show only mandatory review items

2. `cqc reviser approuver`:
   - `indices: str` argument -- comma-separated list of row numbers or "all" or "optionnel" (approves all 80-95%)
   - Parse indices (e.g., "1,3,5" or "1-5" or "all")
   - Call `approuver_transactions()` for selected indices
   - Validate ledger after approval. If validation fails, show error and rollback.
   - Git auto-commit: `"reviser: approuve {N} transactions"`
   - Print summary: "N transactions approuvees et deplacees vers le ledger."

3. `cqc reviser rejeter`:
   - `indices: str` argument -- comma-separated row numbers
   - Call `rejeter_transactions()` for selected indices
   - Git auto-commit: `"reviser: rejete {N} transactions"`
   - Print confirmation

4. `cqc reviser recategoriser`:
   - `indice: int` argument -- single row number
   - `compte: str` argument -- new account to assign
   - Validate `compte` against chart of accounts (load from main.beancount)
   - Load the pending transaction, update its account posting and metadata
   - Call `enregistrer_correction()` from feedback module -- pass vendeur, new account, old account
   - If auto-rule generated: print info "Nouvelle regle auto-generee pour {vendeur} -> {compte}"
   - Prompt for optional note: `note = Prompt.ask("Note (optionnel)", default="")`
   - Move corrected transaction to monthly file (it's been human-verified)
   - Validate ledger. If invalid, rollback.
   - Git auto-commit: `"reviser: recategorise {vendeur} -> {compte}"`

5. `cqc reviser journal` (optional, for audit):
   - Show recently auto-approved transactions (>95% confidence) that bypassed review
   - Read from monthly files, filter by metadata `source_ia` in ("ml", "llm") and `confiance` > 0.95
   - Display in same table format but with green styling

6. `cqc retrain` (separate command on main app, not sub-app):
   - Trigger ML retraining from approved ledger data
   - Call `PredicteurML.entrainer()` with all non-pending entries
   - Show training summary: "Modele ML entraine sur N transactions, K comptes distincts"
   - Save trained model to `data/ml/modele.pkl` (joblib)

**Register in main CLI app** (`src/compteqc/cli/app.py`):
- Import `reviser_app` from `compteqc.cli.reviser`
- `app.add_typer(reviser_app, name="reviser", help="Reviser les transactions en attente")`
- Add `retrain` command to main app

Write tests in `tests/test_reviser.py`:
- List command shows pending transactions in correct table format
- Approve command moves transactions from pending to monthly file
- Reject command removes transactions from pending
- Recategorize command updates account and triggers correction tracking
- Auto-rule generation fires after 2 identical recategorizations
- Filter by --obligatoire shows only <80% confidence items
- Empty pending list shows "aucune transaction" message
- Invalid account in recategorize shows error

Use isolated tmp_path ledger setup (same pattern as existing CLI tests).
  </action>
  <verify>
`cd /Users/philippebeliveau/Desktop/Notebook/comptabilite && uv run pytest tests/test_reviser.py tests/test_feedback.py -v` all pass. `uv run pytest tests/ -v` full test suite passes. `uv run ruff check src/compteqc/` no lint errors.
  </verify>
  <done>Complete review workflow: list pending with Rich table, approve/reject/recategorize with feedback loop, auto-rule generation after 2 corrections, retrain command for ML. All registered in main CLI app.</done>
</task>

</tasks>

<verification>
- `uv run pytest tests/ -v` -- full test suite passes (all phases)
- `uv run ruff check src/compteqc/` -- no lint errors
- `cqc reviser liste` shows pending transactions with correct formatting
- `cqc reviser approuver 1,2,3` moves transactions and commits
- `cqc reviser recategoriser 1 Depenses:Bureau:Fournitures` updates and tracks correction
- After 2 identical recategorizations, a rule appears in categorisation.yaml
- `cqc retrain` trains ML model without errors
</verification>

<success_criteria>
- Batch review table displays all required columns with confidence color-coding
- Mandatory vs optional review items are visually separated
- Approve/reject/recategorize all work correctly with ledger validation and git commits
- Corrections feed into rule engine with auto-generation after 2 identical corrections
- ML retrain command works as manual trigger
- Full end-to-end: import -> AI categorize -> pending -> review -> approve -> ledger
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-categorization-and-review-workflow/03-03-SUMMARY.md`
</output>
